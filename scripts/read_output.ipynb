{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bb00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from NNetwork import NNetwork as nn\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import os\n",
    "# Cloud \n",
    "import boto3\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from firthlogist import FirthLogisticRegression\n",
    "\n",
    "# =======================================================\n",
    "# Connect to S3 resource\n",
    "# =======================================================\n",
    "# connect to S3 and create resource object\n",
    "s3_resource = boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name='us-west-1',\n",
    "            aws_access_key_id='AKIAWNJSAXHUWYXA4YJF',\n",
    "            aws_secret_access_key='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'\n",
    "            )\n",
    "s3_client = boto3.client('s3', \n",
    "            aws_access_key_id='AKIAWNJSAXHUWYXA4YJF',\n",
    "            aws_secret_access_key='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')\n",
    "\n",
    "# specify bucket object\n",
    "s3_bucket = s3_resource.Bucket('interpretable-sync')\n",
    "objects = s3_client.list_objects_v2(Bucket='interpretable-sync')\n",
    "allkeys = [obj['Key'] for obj in objects['Contents']]\n",
    "\n",
    "\n",
    "ntwk_names = ['nws-20000-1000-05']#['Caltech36', 'nws-20000-1000-05', 'UCLA26'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9478de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theory driven nmflog\n",
    "df = []\n",
    "for ntwk in ['UCLA26']:#'Caltech36', 'nws-20000-1000-05', 'UCLA26']:\n",
    "    for num_nodes in [25]:#[10, 15, 20, 25, 30]:\n",
    "        for ca in [\"ghm\"]:#[\"kura\", \"fca\", \"ghm\"]:\n",
    "            filename = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_DYNAMIC-\"+ca\n",
    "            filename_logreg = filename+\"_theory_driven_logreg-r1.pkl\"\n",
    "            filename_xy = \"../data/sdl_xy/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_DYNAMIC-\"+ca+\".pkl\"\n",
    "            \n",
    "            if filename_logreg not in allkeys:\n",
    "                df.append([ntwk, num_nodes, ca, \n",
    "                        np.nan])\n",
    "            else:\n",
    "                temp = pickle.loads(s3_bucket.Object(filename_logreg).get()['Body'].read())\n",
    "                if temp[\"summary\"] == \"perfect separation\":\n",
    "                    df.append([ntwk, num_nodes, ca, \"perfect separation\"])\n",
    "                else:\n",
    "    \n",
    "                    table = pd.read_html(temp[\"summary\"].tables[1].as_html(),header=0,index_col=0)[0]\n",
    "\n",
    "                    y_pred = temp['predict_prob'].round()\n",
    "\n",
    "                    y_test = pickle.load(open(filename_xy, 'rb'))['y_test']\n",
    "                    if ca == \"ghm\":\n",
    "                        df.append([ntwk, num_nodes, ca, \n",
    "                                   table.coef[0], table.coef[1],  np.nan, np.nan,\n",
    "                                   table.z[0], table.z[1], np.nan, np.nan,\n",
    "                                   table[\"P>|z|\"][0], table[\"P>|z|\"][1],  np.nan,  np.nan,\n",
    "                                   accuracy_score(y_test, y_pred), precision_score(y_test, y_pred),\n",
    "                                   recall_score(y_test, y_pred), f1_score(y_test, y_pred)])\n",
    "                    else:\n",
    "                        df.append([ntwk, num_nodes, ca, \n",
    "                                   table.coef[0], table.coef[1], table.coef[2], table.coef[3],\n",
    "                                   table.z[0], table.z[1], table.z[2], table.z[3],\n",
    "                                   table[\"P>|z|\"][0], table[\"P>|z|\"][1], table[\"P>|z|\"][2], table[\"P>|z|\"][3],\n",
    "                                   accuracy_score(y_test, y_pred), precision_score(y_test, y_pred),\n",
    "                                   recall_score(y_test, y_pred), f1_score(y_test, y_pred)])\n",
    "#pd.DataFrame(df).to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d954cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theory driven nmflog\n",
    "df = []\n",
    "for ntwk in ['UCLA26']:#'Caltech36', 'nws-20000-1000-05', 'UCLA26']:\n",
    "    for num_nodes in [30]:#[10, 15, 20, 25, 30]:\n",
    "        for ca in [\"kura\"]:\n",
    "            filename = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_DYNAMIC-\"+ca\n",
    "            filename_logreg = filename+\"_sdl-r4.pkl\"\n",
    "            t = pickle.loads(s3_bucket.Object(filename_logreg).get()['Body'].read())\n",
    "            df.append([t['AUC'], t['Accuracy'], t['Recall'], t['Precision'], t['F_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caae621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xi': 1,\n",
       " 'L1_reg': [0, 0, 0],\n",
       " 'L2_reg': [0, 0, 0],\n",
       " 'nonnegativity': [True, True, False],\n",
       " 'n_components': 4,\n",
       " 'loading': [array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.03578603e-17],\n",
       "         [7.81805370e-03, 1.86710061e-03, 1.32975209e-02, 4.24781354e-03],\n",
       "         [1.23021678e-03, 2.02504974e-04, 1.36160638e-03, 5.64772287e-04],\n",
       "         ...,\n",
       "         [9.79075538e-04, 4.41036626e-04, 1.62321680e-04, 2.96807659e-05],\n",
       "         [3.71801746e-04, 1.84798453e-04, 6.77107299e-05, 3.26323764e-05],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.32862900e-17]]),\n",
       "  array([[ 0.82879459,  0.09267081, -0.33532097,  0.36834854, -0.19867604]])],\n",
       " 'code': array([[28.56206129, 21.61394116, 27.15132763, ...,  4.65747735,\n",
       "          7.19075541,  5.05341386],\n",
       "        [ 8.91391713, 47.8805967 , 44.0191633 , ..., 39.36565263,\n",
       "          5.43704105, 20.12174298],\n",
       "        [31.6057884 , 52.00550406, 55.27776122, ..., 77.53647415,\n",
       "         64.10720734, 47.6317916 ],\n",
       "        [88.76641983, 52.1898981 , 50.5680298 , ..., 29.77137548,\n",
       "          5.09461877,  0.        ]]),\n",
       " 'iter': 100,\n",
       " 'dict_update_freq': 1,\n",
       " 'Training_threshold': 0.5276551513866681,\n",
       " 'code_test': array([[16.03791832, 35.25432022, 23.6972621 , ..., 26.40921931,\n",
       "         20.92668219, 21.21545323],\n",
       "        [13.54955348, 29.91359893, 22.91457979, ..., 29.22909039,\n",
       "         19.18364806, 32.62009513],\n",
       "        [17.36810158, 27.98574625, 21.08384185, ..., 20.33724962,\n",
       "         18.69829567, 22.99127444],\n",
       "        [13.07897304, 35.09176397, 24.60714028, ..., 22.04571642,\n",
       "         20.46334349, 27.69610261]]),\n",
       " 'P_pred': array([[0.82787315],\n",
       "        [0.06925435],\n",
       "        [0.14411222],\n",
       "        ...,\n",
       "        [0.03186917],\n",
       "        [0.30097096],\n",
       "        [0.00561265]]),\n",
       " 'Y_hat': array([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'Relative_reconstruction_loss (test)': 0.4741698495182891,\n",
       " 'Y_test': array([[ True, False, False, ..., False,  True, False]]),\n",
       " 'Y_pred': array([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'AUC': 0.9396504401553066,\n",
       " 'Opt_threshold': 0.46541729521754543,\n",
       " 'Accuracy': 0.8711960368011323,\n",
       " 'Misclassification': 0.12880396319886767,\n",
       " 'Precision': 0.891044776119403,\n",
       " 'Recall': 0.8456090651558074,\n",
       " 'Sensitivity': 0.8456090651558074,\n",
       " 'Specificity': 0.8967468175388967,\n",
       " 'F_score': 0.8677325581395349,\n",
       " 'Fall_out': 0.10325318246110325,\n",
       " 'Miss_rate': 0.15439093484419264}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132ca4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82de1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loading beta [[-0.82836581  0.47936959 -0.85884328 -0.32346143 -0.54006264]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [06:09<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "0.9964788732394366\n",
      "                 coef    std err     [0.025     0.975]      p-value\n",
      "---------  ----------  ---------  ---------  ---------  -----------\n",
      "x1          0.0823932   0.222593  -0.35388    0.518667  0.711269\n",
      "x2         -0.282773    0.045561  -0.372071  -0.193475  5.41931e-10\n",
      "Intercept   7.88755     5.00433   -1.92075   17.6958    0.114992\n",
      "\n",
      "Log-Likelihood: 3.4574\n",
      "Newton-Raphson iterations: 25\n",
      "\n",
      "None\n",
      "1.0\n",
      "                 coef    std err     [0.025     0.975]      p-value\n",
      "---------  ----------  ---------  ---------  ---------  -----------\n",
      "x1          0.0823932   0.222593  -0.35388    0.518667  0.711269\n",
      "x2         -0.282773    0.045561  -0.372071  -0.193475  5.41931e-10\n",
      "Intercept   7.88755     5.00433   -1.92075   17.6958    0.114992\n",
      "\n",
      "Log-Likelihood: 3.4574\n",
      "Newton-Raphson iterations: 25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loading beta [[ 0.53175916 -0.93358363  0.80487997 -0.68868655  0.86664011]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:19<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "Theory driven SDL0.9894366197183099\n"
     ]
    }
   ],
   "source": [
    "ntwk_names = ['UCLA26'] #'nws-20000-1000-05', 'Caltech36', \n",
    "for ntwk in ntwk_names:\n",
    "    for num_nodes in [25]:#[10, 15, 20, 25, 30]:\n",
    "        for ca in [\"ghm\"]:#[\"kura\", \"fca\", \"ghm\"]:\n",
    "            #data driven sdl\n",
    "            xy = pickle.loads(s3_bucket.Object(\"sdl_xy/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+\".pkl\").get()['Body'].read())\n",
    "            \n",
    "            X_train = xy[\"X_train\"]\n",
    "            y_train = xy[\"y_train\"]\n",
    "            X_test = xy[\"X_test\"]\n",
    "            y_test = xy[\"y_test\"]\n",
    "            xi = 1\n",
    "            iter_avg = 1\n",
    "            beta = 0.5\n",
    "            iteration = 100\n",
    "            r = 4\n",
    "            SDL_BCD_class_new = SDL_BCD(X=[X_train.T, y_train.to_numpy().reshape(-1,1).T],  # data, label\n",
    "                                    X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                                    n_components=r, xi=xi, L1_reg = [0,0,0], L2_reg = [0,0,0], \n",
    "                                    nonnegativity=[True,True,False],full_dim=False)\n",
    "            results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                            beta = beta,\n",
    "                                                            search_radius_const=np.linalg.norm(X_train),\n",
    "                                                            update_nuance_param=False,\n",
    "                                                            if_compute_recons_error=False, if_validate=False)\n",
    "            print(results_dict_new[\"Accuracy\"])\n",
    "            s3_bucket.put_object(Body= pickle.dumps(results_dict_new), \n",
    "                                 Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_sdl-r4.pkl')\n",
    "            \n",
    "            if ntwk != 'nws-20000-1000-05':\n",
    "                #theory driven nmf+logreg\n",
    "                W = pickle.loads(s3_bucket.Object(\"output/SAMPLES-10000_NTWK-nws-20000-1000-05_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-r1.pkl').get()['Body'].read())\n",
    "                model = FirthLogisticRegression(wald=True)\n",
    "                model.fit(np.matmul(W, X_train.T).T, y_train)\n",
    "                print(model.summary())\n",
    "                print(accuracy_score(y_test, model.predict(np.matmul(W, X_test.T).T).round()))\n",
    "                logreg = {\"summary\": model.summary(),\n",
    "                         \"predict_prob\": model.predict(np.matmul(W, X_test.T).T)}\n",
    "                s3_bucket.put_object(Body=pickle.dumps(logreg), \n",
    "                                     Key = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_logreg-r1.pkl')\n",
    "                \n",
    "                #theory driven sdl\n",
    "                data_dict = pickle.loads(s3_bucket.Object(\"output/SAMPLES-10000_NTWK-nws-20000-1000-05_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-examples-dict.pkl').get()['Body'].read())\n",
    "                \n",
    "                xi = 1\n",
    "                iter_avg = 1\n",
    "                beta = 0.5\n",
    "                iteration = 100\n",
    "                r = 4\n",
    "                if ca == \"ghm\":\n",
    "                    SDL_BCD_class_new = SDL_BCD(X=[np.concatenate([data_dict[\"x_dense\"],\n",
    "                                                                   data_dict[\"x_sparse\"]]).T,\n",
    "                                                np.concatenate([data_dict[\"y_dense\"],\n",
    "                                                               data_dict[\"y_sparse\"]]).reshape(-1,1).T],  # data, label\n",
    "                                        X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                                        n_components=r, xi=xi, L1_reg = [0,0,0], L2_reg = [0,0,0], \n",
    "                                        nonnegativity=[True,True,False],full_dim=False)\n",
    "                    results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                                beta = beta, search_radius_const = np.linalg.norm(X_train), update_nuance_param=False, if_compute_recons_error=False, if_validate=False)\n",
    "                    print(\"Theory driven SDL\"+ str(results_dict_new[\"Accuracy\"]))\n",
    "                    s3_bucket.put_object(Body=pickle.dumps(results_dict_new),\n",
    "                                         Key = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdlsdl-r4.pkl')\n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5aba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
