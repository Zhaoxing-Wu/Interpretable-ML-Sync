{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bb00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from NNetwork import NNetwork as nn\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import os\n",
    "# Cloud \n",
    "import boto3\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from firthlogist import FirthLogisticRegression\n",
    "\n",
    "# =======================================================\n",
    "# Connect to S3 resource\n",
    "# =======================================================\n",
    "# connect to S3 and create resource object\n",
    "s3_resource = boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name='us-west-1',\n",
    "            aws_access_key_id='AKIAWNJSAXHUWYXA4YJF',\n",
    "            aws_secret_access_key='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'\n",
    "            )\n",
    "s3_client = boto3.client('s3', \n",
    "            aws_access_key_id='AKIAWNJSAXHUWYXA4YJF',\n",
    "            aws_secret_access_key='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')\n",
    "\n",
    "# specify bucket object\n",
    "s3_bucket = s3_resource.Bucket('interpretable-sync')\n",
    "objects = s3_client.list_objects_v2(Bucket='interpretable-sync')\n",
    "allkeys = [obj['Key'] for obj in objects['Contents']]\n",
    "\n",
    "\n",
    "ntwk_names = ['nws-20000-1000-05']#['Caltech36', 'nws-20000-1000-05', 'UCLA26'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d93f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifDynamics/SAMPLES-10000_NTWK-nws-20000-1000-05_K-10_COLADJ-kura_PARAMS-csv.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                         | 4/100 [00:00<00:02, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 coef    std err      [0.025      0.975]       p-value\n",
      "---------  ----------  ---------  ----------  ----------  ------------\n",
      "x1          1.62483    0.179684    1.27265     1.977      1.5287e-19\n",
      "x2         -3.0231     0.221294   -3.45683    -2.58937    1.7357e-42\n",
      "x3          0.606846   0.283314    0.0515599   1.16213    0.0321973\n",
      "x4         -0.0147395  0.0491595  -0.11109     0.0816114  0.764308\n",
      "Intercept  17.6298     0.652436   16.3511     18.9086     8.26013e-161\n",
      "\n",
      "Log-Likelihood: -1218.1253\n",
      "Newton-Raphson iterations: 7\n",
      "\n",
      "None\n",
      "0.8259423503325942\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539972\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3604\n",
      "Model:                          Logit   Df Residuals:                     3600\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 19 Nov 2022   Pseudo R-squ.:                  0.2210\n",
      "Time:                        10:27:29   Log-Likelihood:                -1946.1\n",
      "converged:                       True   LL-Null:                       -2498.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.726e-239\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             2.4121      0.150     16.104      0.000       2.119       2.706\n",
      "x2            -3.7280      0.184    -20.315      0.000      -4.088      -3.368\n",
      "x3             1.3643      0.226      6.039      0.000       0.922       1.807\n",
      "x4            -0.0093      0.039     -0.241      0.809      -0.085       0.067\n",
      "==============================================================================\n",
      "0.7184035476718403\n",
      "initial loading beta [[-0.82210129 -0.60814663  0.10297698  0.43847145  0.48768336]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:02<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "Theory driven SDL0.7993348115299335\n",
      "motifDynamics/SAMPLES-10000_NTWK-nws-20000-1000-05_K-10_COLADJ-fca_PARAMS-csv.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                         | 4/100 [00:00<00:02, 36.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 coef    std err     [0.025     0.975]      p-value\n",
      "---------  ----------  ---------  ---------  ---------  -----------\n",
      "x1         -0.37229     0.111049  -0.589942  -0.154639  0.000800877\n",
      "x2          0.0376453   0.140613  -0.23795    0.313241  0.788912\n",
      "x3          2.72512     0.13012    2.47009    2.98015   2.17054e-97\n",
      "x4         -2.75131     0.2078    -3.15859   -2.34403   5.14363e-40\n",
      "Intercept   4.93955     0.721957   3.52454    6.35456   7.81558e-12\n",
      "\n",
      "Log-Likelihood: -942.2657\n",
      "Newton-Raphson iterations: 7\n",
      "\n",
      "None\n",
      "0.9060324825986079\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284599\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3446\n",
      "Model:                          Logit   Df Residuals:                     3442\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 19 Nov 2022   Pseudo R-squ.:                  0.5894\n",
      "Time:                        10:29:50   Log-Likelihood:                -980.73\n",
      "converged:                       True   LL-Null:                       -2388.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1743      0.078      2.230      0.026       0.021       0.328\n",
      "x2             0.2519      0.138      1.831      0.067      -0.018       0.522\n",
      "x3             2.8446      0.130     21.842      0.000       2.589       3.100\n",
      "x4            -3.2495      0.198    -16.430      0.000      -3.637      -2.862\n",
      "==============================================================================\n",
      "0.9071925754060325\n",
      "initial loading beta [[-0.48122363 -0.64294412 -0.9720751   0.56184974 -0.44859306]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:02<00:00, 45.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "Theory driven SDL0.8016241299303944\n",
      "motifDynamics/SAMPLES-10000_NTWK-nws-20000-1000-05_K-10_COLADJ-ghm_PARAMS-csv.pkl\n",
      "\n",
      "               coef    std err     [0.025     0.975]      p-value\n",
      "---------  --------  ---------  ---------  ---------  -----------\n",
      "x1          1.17327   0.653546  -0.107651   2.4542    0.0726146\n",
      "x2         -1.02703   0.207954  -1.43461   -0.619448  7.86269e-07\n",
      "Intercept   2.51292   4.96313   -7.21464   12.2405    0.612634\n",
      "\n",
      "Log-Likelihood: 1.2635\n",
      "Newton-Raphson iterations: 25\n",
      "\n",
      "None\n",
      "1.0\n"
     ]
    },
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mmatmul(W, X_test\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mround()))\n\u001b[0;32m---> 95\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnewton\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mmatmul(W, X_test\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mround()))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:1974\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   1973\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1974\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1978\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1979\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1980\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1982\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   1983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:227\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:519\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m warn_convergence \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn_convergence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    518\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[0;32m--> 519\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# NOTE: this is for fit_regularized and should be generalized\u001b[39;00m\n\u001b[1;32m    530\u001b[0m cov_params_func \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov_params_func\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/optimizer.py:224\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    221\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    223\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 224\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall}\n\u001b[1;32m    233\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/optimizer.py:426\u001b[0m, in \u001b[0;36m_fit_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[1;32m    424\u001b[0m         history\u001b[38;5;241m.\u001b[39mappend(newparams)\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    428\u001b[0m fval \u001b[38;5;241m=\u001b[39m f(newparams, \u001b[38;5;241m*\u001b[39mfargs)  \u001b[38;5;66;03m# this is the negative likelihood\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/discrete/discrete_model.py:211\u001b[0m, in \u001b[0;36mDiscreteModel._check_perfect_pred\u001b[0;34m(self, params, *args)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_on_perfect_prediction \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    209\u001b[0m         np\u001b[38;5;241m.\u001b[39mallclose(fittedvalues \u001b[38;5;241m-\u001b[39m endog, \u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m    210\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerfect separation detected, results not available\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PerfectSeparationError(msg)\n",
      "\u001b[0;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "for ntwk in ['nws-20000-1000-05']:\n",
    "    for num_nodes in [10]:#, 15, 20, 25, 30]:\n",
    "        #read X\n",
    "        ntwk_filename = \"motifSampling/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_PATCHES.pkl\"\n",
    "        feature_filename = \"motifSampling/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_graph_features.csv\"\n",
    "        xEmbDes = pickle.loads(s3_bucket.Object(ntwk_filename).get()['Body'].read())\n",
    "        df_feature = pickle.loads(s3_bucket.Object(feature_filename).get()['Body'].read())\n",
    "        if ntwk == \"nws-20000-1000-05\":\n",
    "            X = xEmbDes\n",
    "        else:\n",
    "            X = xEmbDes['X']\n",
    "            \n",
    "        for ca in [\"kura\", \"fca\", \"ghm\"]:\n",
    "            name_dynamics = \"motifDynamics/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "            df_dynamics = pickle.loads(s3_bucket.Object(name_dynamics).get()['Body'].read())\n",
    "            #############################CHANGE########################################\n",
    "            name_coladj = \"motifDynamics/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_COLADJ-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "            df_coladj = pickle.loads(s3_bucket.Object(name_coladj).get()['Body'].read())\n",
    "            #############################CHANGE########################################\n",
    "            print(name_coladj+\"\\n\")\n",
    "            \n",
    "            #theory driven\n",
    "            if ntwk == \"nws-20000-1000-05\":\n",
    "                sample_size = 100 #number of samples used for learning dictionary\n",
    "                ind_dense = df_feature[df_dynamics.y == True].sort_values(by='density').index[-sample_size:].tolist()\n",
    "                ind_sparse = df_feature[df_dynamics.y == False][df_feature.is_tree != True].sort_values(by='density').index[:sample_size].tolist()   \n",
    "                ind_con = df_dynamics[df_dynamics.baseline_width==True].index.tolist()\n",
    "                if len(ind_con)>sample_size:\n",
    "                    ind_con = ind_con[:sample_size]\n",
    "                    \n",
    "                X_comb = pd.concat([pd.DataFrame(X.T), df_coladj/max(df_coladj.max())], axis=1)\n",
    "\n",
    "\n",
    "                r = 1\n",
    "                W_dense, H_dense = ALS(X=X_comb.loc[ind_dense,].T.values, \n",
    "                                       n_components=r, n_iter=100, a0 = 0, a1 = 0, a12 = 0, H_nonnegativity=True, \n",
    "                                       W_nonnegativity=True, compute_recons_error=True, subsample_ratio=1)\n",
    "                W_sparse, H_sparse = ALS(X=X_comb.loc[ind_sparse,].T.values, \n",
    "                                         n_components=r, n_iter=100, a0 = 0, a1 = 0, a12 = 0, \n",
    "                                         H_nonnegativity=True, W_nonnegativity=True, \n",
    "                                         compute_recons_error=True, subsample_ratio=1)\n",
    "                \n",
    "                data_dict = {}\n",
    "                data_dict[\"x_dense\"] = X_comb.loc[ind_dense,]\n",
    "                data_dict[\"y_dense\"] = df_dynamics.y[ind_dense]\n",
    "                data_dict[\"x_sparse\"] = X_comb.loc[ind_sparse,]\n",
    "                data_dict[\"y_sparse\"] = df_dynamics.y[ind_sparse]\n",
    "                \n",
    "                if ca != \"ghm\": \n",
    "                    data_dict[\"x_concentrated\"] = X_comb.loc[ind_con,]\n",
    "                    data_dict[\"y_concentrated\"] = df_dynamics.y[ind_con]\n",
    "                    \n",
    "                    dynamicstree_filename = \"motifDynamics/SAMPLES-100_NTWK-tree_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "                    coladjtree_filename = \"motifDynamics/SAMPLES-100_NTWK-tree_K-\"+str(num_nodes)+'_COLADJ-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "                    ntwktree_filename = \"motifSampling/SAMPLES-100_NTWK-tree_K-\"+str(num_nodes)+\"_PATCHES.pkl\"\n",
    "                    X_tree = pickle.loads(s3_bucket.Object(ntwktree_filename).get()['Body'].read())\n",
    "                    df_dynamicstree = pickle.loads(s3_bucket.Object(dynamicstree_filename).get()['Body'].read())\n",
    "                    df_coladjtree = pickle.loads(s3_bucket.Object(coladjtree_filename).get()['Body'].read())\n",
    "                    X_tree_comb = pd.concat([pd.DataFrame(X_tree.T), df_coladjtree/max(df_coladjtree.max())], axis=1)[df_dynamicstree.y==True]\n",
    "\n",
    "                    W_con, H_con = ALS(X=X_comb.loc[ind_con,].T.values, n_components=r, \n",
    "                                       n_iter=100, a0 = 0, a1 = 0, a12 = 0, H_nonnegativity=True, \n",
    "                                       W_nonnegativity=True, compute_recons_error=True, subsample_ratio=1)\n",
    "                    W_tree, H_tree = ALS(X=X_tree_comb.T.values, n_components=r, \n",
    "                                       n_iter=100, a0 = 0, a1 = 0, a12 = 0, H_nonnegativity=True, \n",
    "                                       W_nonnegativity=True, compute_recons_error=True, subsample_ratio=1)\n",
    "                    \n",
    "                    data_dict[\"x_tree\"] = X_tree_comb\n",
    "                    data_dict[\"y_tree\"] = df_dynamicstree.y[df_dynamicstree.y==True]\n",
    "                    \n",
    "                    W = np.concatenate([W_dense.T, W_sparse.T, W_con.T, W_tree.T])\n",
    "                else:\n",
    "                    W = np.concatenate([W_dense.T, W_sparse.T])\n",
    "                    \n",
    "                #s3_bucket.put_object(Body=pickle.dumps(W), \n",
    "                 #                    Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-r1.pkl')\n",
    "                \n",
    "                #s3_bucket.put_object(Body=pickle.dumps(data_dict), \n",
    "                 #                    Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-examples-dict.pkl')\n",
    "                \n",
    "                Y_data = df_dynamics.y\n",
    "                under_sampler = RandomUnderSampler()\n",
    "                X_res, y_res = under_sampler.fit_resample(X_comb.values, Y_data)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 4, \n",
    "                                                    stratify = y_res)\n",
    "                \n",
    "                                \n",
    "                model = FirthLogisticRegression(wald=True)\n",
    "                model.fit(np.matmul(W, X_train.T).T, y_train)\n",
    "\n",
    "                print(model.summary())\n",
    "                print(accuracy_score(y_test, model.predict(np.matmul(W, X_test.T).T).round()))\n",
    "                logreg = {\"summary\": model.summary(),\n",
    "                         \"predict_prob\": model.predict(np.matmul(W, X_test.T).T)}\n",
    "                #s3_bucket.put_object(Body=pickle.dumps(logreg), \n",
    "                 #                    Key = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_logreg-r1.pkl')\n",
    "                    \n",
    "                xi = 1\n",
    "                iter_avg = 1\n",
    "                beta = 0.5\n",
    "                iteration = 100\n",
    "                r = 4\n",
    "                if ca == \"ghm\":\n",
    "                    SDL_BCD_class_new = SDL_BCD(X=[np.concatenate([data_dict[\"x_dense\"],\n",
    "                                                                   data_dict[\"x_sparse\"]]).T,\n",
    "                                                np.concatenate([data_dict[\"y_dense\"],\n",
    "                                                               data_dict[\"y_sparse\"]]).reshape(-1,1).T],  # data, label\n",
    "                                        X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                                        n_components=r, xi=xi, L1_reg = [0,0,0], L2_reg = [0,0,0], \n",
    "                                        nonnegativity=[True,True,False],full_dim=False)\n",
    "                    results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                                beta = beta, search_radius_const = np.linalg.norm(X_train), update_nuance_param=False, if_compute_recons_error=False, if_validate=False)\n",
    "                    print(\"Theory driven SDL\"+ str(results_dict_new[\"Accuracy\"]))\n",
    "                    s3_bucket.put_object(Body=pickle.dumps(results_dict_new),\n",
    "                                         Key = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdlsdl-r4.pkl')\n",
    "                \n",
    "                else:\n",
    "                    SDL_BCD_class_new = SDL_BCD(X=[np.concatenate([data_dict[\"x_dense\"],\n",
    "                                                                   data_dict[\"x_sparse\"], \n",
    "                                                                   data_dict[\"x_concentrated\"], \n",
    "                                                                   data_dict[\"x_tree\"]]).T,\n",
    "                                                np.concatenate([data_dict[\"y_dense\"],\n",
    "                                                               data_dict[\"y_sparse\"], \n",
    "                                                               data_dict[\"y_concentrated\"], \n",
    "                                                               data_dict[\"y_tree\"]]).reshape(-1,1).T],  # data, label\n",
    "                                        X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                                        n_components=r, xi=xi, L1_reg = [0,0,0], L2_reg = [0,0,0], \n",
    "                                        nonnegativity=[True,True,False],full_dim=False)\n",
    "                    results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                                beta = beta, search_radius_const = np.linalg.norm(X_train), update_nuance_param=False, if_compute_recons_error=False, if_validate=False)\n",
    "                    print(\"Theory driven SDL\"+ str(results_dict_new[\"Accuracy\"]))\n",
    "                    #s3_bucket.put_object(Body=pickle.dumps(results_dict_new),\n",
    "                    #                     Key = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdlsdl-r4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6374b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
