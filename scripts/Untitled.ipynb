{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bb00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from NNetwork import NNetwork as nn\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import os\n",
    "# Cloud \n",
    "import boto3\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# =======================================================\n",
    "# Connect to S3 resource\n",
    "# =======================================================\n",
    "# connect to S3 and create resource object\n",
    "s3_resource = boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name='us-west-1',\n",
    "            aws_access_key_id='AKIAWNJSAXHUWYXA4YJF',\n",
    "            aws_secret_access_key='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'\n",
    "            )\n",
    "s3_client = boto3.client('s3', \n",
    "            aws_access_key_id='AKIAWNJSAXHUWYXA4YJF',\n",
    "            aws_secret_access_key='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')\n",
    "\n",
    "# specify bucket object\n",
    "s3_bucket = s3_resource.Bucket('interpretable-sync')\n",
    "objects = s3_client.list_objects_v2(Bucket='interpretable-sync')\n",
    "allkeys = [obj['Key'] for obj in objects['Contents']]\n",
    "\n",
    "\n",
    "ntwk_names = ['nws-20000-1000-05']#['Caltech36', 'nws-20000-1000-05', 'UCLA26'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d93f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifDynamics/SAMPLES-10000_NTWK-nws-20000-1000-05_K-10_COLADJ-kura_PARAMS-csv.pkl\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.527275\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3604\n",
      "Model:                          Logit   Df Residuals:                     3600\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 17 Nov 2022   Pseudo R-squ.:                  0.2393\n",
      "Time:                        16:32:22   Log-Likelihood:                -1900.3\n",
      "converged:                       True   LL-Null:                       -2498.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.585e-259\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             2.4575      0.152     16.151      0.000       2.159       2.756\n",
      "x2            -3.8807      0.182    -21.375      0.000      -4.237      -3.525\n",
      "x3             1.4256      0.224      6.369      0.000       0.987       1.864\n",
      "x4             0.0408      0.040      1.032      0.302      -0.037       0.118\n",
      "==============================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(y_train, np\u001b[38;5;241m.\u001b[39mmatmul(W, X_train\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mfit(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, \u001b[43mresult\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mmatmul(W, X_test\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mround()))\n\u001b[1;32m     87\u001b[0m logreg \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39msummary(),\n\u001b[1;32m     88\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mmatmul(W, X_test\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT)}\n\u001b[1;32m     89\u001b[0m s3_bucket\u001b[38;5;241m.\u001b[39mput_object(Body\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mdumps(logreg), \n\u001b[1;32m     90\u001b[0m                      Key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/SAMPLES-10000_NTWK-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mntwk\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_K-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(num_nodes)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_DYNAMIC-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(ca)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_theory_driven_logreg-r4.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "for ntwk in ntwk_names:\n",
    "    for num_nodes in [10]:#, 15, 20, 25, 30]:\n",
    "        #read X\n",
    "        ntwk_filename = \"motifSampling/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_PATCHES.pkl\"\n",
    "        feature_filename = \"motifSampling/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+\"_graph_features.csv\"\n",
    "        xEmbDes = pickle.loads(s3_bucket.Object(ntwk_filename).get()['Body'].read())\n",
    "        df_feature = pickle.loads(s3_bucket.Object(feature_filename).get()['Body'].read())\n",
    "        if ntwk == \"nws-20000-1000-05\":\n",
    "            X = xEmbDes\n",
    "        else:\n",
    "            X = xEmbDes['X']\n",
    "            \n",
    "        for ca in [\"kura\", \"fca\", \"ghm\"]:\n",
    "            temp = [ca, num_nodes, ntwk]\n",
    "            name_dynamics = \"motifDynamics/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "            df_dynamics = pickle.loads(s3_bucket.Object(name_dynamics).get()['Body'].read())\n",
    "            #############################CHANGE########################################\n",
    "            name_coladj = \"motifDynamics/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_COLADJ-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "            df_coladj = pickle.loads(s3_bucket.Object(name_coladj).get()['Body'].read())\n",
    "            #############################CHANGE########################################\n",
    "            print(name_coladj+\"\\n\")\n",
    "            \n",
    "            #theory driven\n",
    "            if ntwk == \"nws-20000-1000-05\":\n",
    "                sample_size = 100 #number of samples used for learning dictionary\n",
    "                ind_dense = df_feature[df_dynamics.y == True].sort_values(by='density').index[-sample_size:].tolist()\n",
    "                ind_sparse = df_feature[df_dynamics.y == False][df_feature.is_tree != True].sort_values(by='density').index[:sample_size].tolist()   \n",
    "                ind_con = df_dynamics[df_dynamics.baseline_width==True].index.tolist()\n",
    "                if len(ind_con)>sample_size:\n",
    "                    ind_con = ind_con[:sample_size]\n",
    "                    \n",
    "                X_comb = pd.concat([pd.DataFrame(X.T), df_coladj/max(df_coladj.max())], axis=1)\n",
    "\n",
    "\n",
    "                r = 1\n",
    "                W_dense, H_dense = ALS(X=X_comb.loc[ind_dense,].T.values, \n",
    "                                       n_components=r, n_iter=100, a0 = 0, a1 = 0, a12 = 0, H_nonnegativity=True, \n",
    "                                       W_nonnegativity=True, compute_recons_error=True, subsample_ratio=1)\n",
    "                W_sparse, H_sparse = ALS(X=X_comb.loc[ind_sparse,].T.values, \n",
    "                                         n_components=r, n_iter=100, a0 = 0, a1 = 0, a12 = 0, \n",
    "                                         H_nonnegativity=True, W_nonnegativity=True, \n",
    "                                         compute_recons_error=True, subsample_ratio=1)\n",
    "                \n",
    "                data_dict = {}\n",
    "                data_dict[\"dense\"] = X_comb.loc[ind_dense,]\n",
    "                data_dict[\"sparse\"] = X_comb.loc[ind_sparse,]\n",
    "                if ca != \"ghm\": \n",
    "                    data_dict[\"concentrated\"] = X_comb.loc[ind_con,]\n",
    "                    \n",
    "                    dynamicstree_filename = \"motifDynamics/SAMPLES-100_NTWK-tree_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "                    coladjtree_filename = \"motifDynamics/SAMPLES-100_NTWK-tree_K-\"+str(num_nodes)+'_COLADJ-'+str(ca)+'_PARAMS-csv.pkl'\n",
    "                    ntwktree_filename = \"motifSampling/SAMPLES-100_NTWK-tree_K-\"+str(num_nodes)+\"_PATCHES.pkl\"\n",
    "                    X_tree = pickle.loads(s3_bucket.Object(ntwktree_filename).get()['Body'].read())\n",
    "                    df_dynamicstree = pickle.loads(s3_bucket.Object(dynamicstree_filename).get()['Body'].read())\n",
    "                    df_coladjtree = pickle.loads(s3_bucket.Object(coladjtree_filename).get()['Body'].read())\n",
    "                    X_tree_comb = pd.concat([pd.DataFrame(X_tree.T), df_coladjtree/max(df_coladjtree.max())], axis=1)[df_dynamicstree.y==True]\n",
    "\n",
    "                    W_con, H_con = ALS(X=X_comb.loc[ind_con,].T.values, n_components=r, \n",
    "                                       n_iter=100, a0 = 0, a1 = 0, a12 = 0, H_nonnegativity=True, \n",
    "                                       W_nonnegativity=True, compute_recons_error=True, subsample_ratio=1)\n",
    "                    W_tree, H_tree = ALS(X=X_tree_comb.T.values, n_components=r, \n",
    "                                       n_iter=100, a0 = 0, a1 = 0, a12 = 0, H_nonnegativity=True, \n",
    "                                       W_nonnegativity=True, compute_recons_error=True, subsample_ratio=1)\n",
    "                    \n",
    "                    data_dict[\"tree\"] = X_tree_comb\n",
    "                    \n",
    "                    W = np.concatenate([W_dense.T, W_sparse.T, W_con.T, W_tree.T])\n",
    "                else:\n",
    "                    W = np.concatenate([W_dense.T, W_sparse.T])\n",
    "                    \n",
    "                s3_bucket.put_object(Body=pickle.dumps(W), \n",
    "                                     Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-r1.pkl')\n",
    "                \n",
    "                s3_bucket.put_object(Body=pickle.dumps(data_dict), \n",
    "                                     Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-examples-dict.pkl')\n",
    "                \n",
    "                Y_data = df_dynamics.y\n",
    "                under_sampler = RandomUnderSampler()\n",
    "                X_res, y_res = under_sampler.fit_resample(X_comb.values, Y_data)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 4, \n",
    "                                                    stratify = y_res)\n",
    "                model = sm.Logit(y_train, np.matmul(W, X_train.T).T).fit(method='newton')\n",
    "                print(model.summary())\n",
    "                print(accuracy_score(y_test, model.predict(np.matmul(W, X_test.T).T).round()))\n",
    "                logreg = {\"summary\": model.summary(),\n",
    "                         \"predict_prob\": model.predict(np.matmul(W, X_test.T).T)}\n",
    "                s3_bucket.put_object(Body=pickle.dumps(logreg), \n",
    "                                     Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_logreg-r4.pkl')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2e8022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loading beta [[-0.05925701  0.15920755  0.16456891 -0.3894349  -0.0508851 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:39<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "0.8082039911308204\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536078\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3604\n",
      "Model:                          Logit   Df Residuals:                     3600\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 17 Nov 2022   Pseudo R-squ.:                  0.2266\n",
      "Time:                        16:58:54   Log-Likelihood:                -1932.0\n",
      "converged:                       True   LL-Null:                       -2498.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.840e-245\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             2.2971      0.149     15.447      0.000       2.006       2.589\n",
      "x2            -3.6946      0.174    -21.266      0.000      -4.035      -3.354\n",
      "x3             1.3743      0.217      6.319      0.000       0.948       1.801\n",
      "x4             0.0662      0.039      1.712      0.087      -0.010       0.142\n",
      "==============================================================================\n",
      "0.7106430155210643\n"
     ]
    }
   ],
   "source": [
    "for ntwk in ntwk_names:\n",
    "    for num_nodes in [10]:#, 15, 20, 25, 30]:\n",
    "        for ca in [\"kura\"]:#, \"fca\", \"ghm\"]:\n",
    "            xy = pickle.loads(s3_bucket.Object(\"sdl_xy/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+\".pkl\").get()['Body'].read())\n",
    "            W = pickle.loads(s3_bucket.Object(\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_sdl-r1.pkl').get()['Body'].read())\n",
    "            \n",
    "            X_train = xy[\"X_train\"]\n",
    "            y_train = xy[\"y_train\"]\n",
    "            X_test = xy[\"X_test\"]\n",
    "            y_test = xy[\"y_test\"]\n",
    "            xi = 1\n",
    "            iter_avg = 1\n",
    "            beta = 0.5\n",
    "            iteration = 100\n",
    "            r = 4\n",
    "            SDL_BCD_class_new = SDL_BCD(X=[X_train.T, y_train.to_numpy().reshape(-1,1).T],  # data, label\n",
    "                                    X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                                    n_components=r, xi=xi, L1_reg = [0,0,0], L2_reg = [0,0,0], \n",
    "                                    nonnegativity=[True,True,False],full_dim=False)\n",
    "            results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                            beta = beta,\n",
    "                                                            search_radius_const=np.linalg.norm(X_train),\n",
    "                                                            update_nuance_param=False,\n",
    "                                                            if_compute_recons_error=False, if_validate=False)\n",
    "            print(results_dict_new[\"Accuracy\"])\n",
    "            s3_bucket.put_object(Body= pickle.dumps(results_dict_new), \n",
    "                                 Key=\"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_sdl-r4.pkl')\n",
    "            \n",
    "            if ntwk == 'nws-20000-1000-05':\n",
    "                model = sm.Logit(y_train, np.matmul(W, X_train.T).T).fit(method='newton')\n",
    "                print(model.summary())\n",
    "                print(accuracy_score(y_test, model.predict(np.matmul(W, X_test.T).T).round()))\n",
    "                logreg = {\"summary\": model.summary(),\n",
    "                         \"predict_prob\": model.predict(np.matmul(W, X_test.T).T)}\n",
    "                s3_bucket.put_object(Body=pickle.dumps(logreg), \n",
    "                                     Key = \"output/SAMPLES-10000_NTWK-\"+ntwk+\"_K-\"+str(num_nodes)+'_DYNAMIC-'+str(ca)+'_theory_driven_logreg-r1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260d5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                          | 3/100 [00:00<00:03, 29.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loading beta [[ 0.45432391  0.79104321  0.35448032 -0.34769383  0.04232881]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:02<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "0.8237250554323725\n"
     ]
    }
   ],
   "source": [
    "SDL_BCD_class_new = SDL_BCD(X=[np.concatenate([X_comb.loc[ind_dense],\n",
    "                                               X_comb.loc[ind_sparse],\n",
    "                                               X_comb.loc[ind_con,],\n",
    "                                               X_tree_comb]).T,\n",
    "                               np.concatenate([df_dynamics.y[ind_dense],\n",
    "                                               df_dynamics.y[ind_sparse],\n",
    "                                               df_dynamics.y[ind_con],\n",
    "                                               df_dynamicstree.y[df_dynamicstree.y==True]]).reshape(-1,1).T],  # data, label\n",
    "                        X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                        n_components=r, xi=xi, L1_reg = [0,0,0], L2_reg = [0,0,0], \n",
    "                        nonnegativity=[True,True,False],full_dim=False)\n",
    "results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                beta = beta,\n",
    "                                                search_radius_const=np.linalg.norm(X_train),\n",
    "                                                update_nuance_param=False,\n",
    "                                                if_compute_recons_error=False, if_validate=False)\n",
    "print(results_dict_new[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a83c1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loading beta [[-0.23957021 -0.03083544 -0.28657253 -0.84466198 -0.8570857 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:38<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "0.8070953436807096\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541205\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3604\n",
      "Model:                          Logit   Df Residuals:                     3600\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 17 Nov 2022   Pseudo R-squ.:                  0.2192\n",
      "Time:                        17:38:55   Log-Likelihood:                -1950.5\n",
      "converged:                       True   LL-Null:                       -2498.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.999e-237\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             2.2727      0.148     15.390      0.000       1.983       2.562\n",
      "x2            -3.7879      0.184    -20.567      0.000      -4.149      -3.427\n",
      "x3             1.5430      0.221      6.990      0.000       1.110       1.976\n",
      "x4             0.0092      0.058      0.160      0.873      -0.104       0.122\n",
      "==============================================================================\n",
      "0.7150776053215078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                         | 5/100 [00:00<00:02, 41.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loading beta [[-0.54787104  0.33881878 -0.91612144  0.51814667  0.68222106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:02<00:00, 39.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! pred_type filter\n",
      "Theory driven SDL0.8170731707317073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2596e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
