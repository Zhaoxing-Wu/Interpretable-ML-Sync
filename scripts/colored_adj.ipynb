{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe5983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b074d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pickle.load(open('../data/random_graph/ucla_20walk_graph.pkl', 'rb'))\n",
    "df_dynamics = pd.read_csv(\"../data/dynamics_pairs/fca_k8_ucla_20walk_dynamics.csv\")\n",
    "y = df_dynamics.y\n",
    "base = df_dynamics.baseline_width\n",
    "df_dynamics = df_dynamics.loc[:, 's1_1':'s50_20']\n",
    "df = pd.read_csv(\"../data/dynamics_pairs/fca_k8_ucla_20walk_colored_adj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge true adj and colored adj side by side\n",
    "scale = 4 # scale down colored adj\n",
    "X = pd.concat([pd.DataFrame(df_graph.T), df/scale], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf48ba",
   "metadata": {},
   "source": [
    "# SDL on colored adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = y\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = under_sampler.fit_resample(X.values, Y_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 4, \n",
    "                                                    stratify = y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 1\n",
    "iter_avg = 1\n",
    "beta = 0.5\n",
    "iteration = 100\n",
    "r = 8\n",
    "SDL_BCD_class_new = SDL_BCD(X=[X_train.T, y_train.to_numpy().reshape(-1,1).T],  # data, label\n",
    "                        X_test=[X_test.T, y_test.to_numpy().reshape(-1,1).T],\n",
    "                        #X_auxiliary = None,\n",
    "                        n_components=r,  # =: r = number of columns in dictionary matrices W, W'\n",
    "                        # ini_loading=None,  # Initializatio for [W,W'], W1.shape = [d1, r], W2.shape = [d2, r]\n",
    "                        # ini_loading=[W_true, np.hstack((np.array([[0]]), Beta_true))],\n",
    "                        # ini_code = H_true,\n",
    "                        xi=xi,  # weight on label reconstruction error\n",
    "                        L1_reg = [0,0,0], # L1 regularizer for code H, dictionary W[0], reg param W[1]\n",
    "                        L2_reg = [0,0,0], # L2 regularizer for code H, dictionary W[0], reg param W[1]\n",
    "                        nonnegativity=[True,True,False], # nonnegativity constraints on code H, dictionary W[0], reg params W[1]\n",
    "                        full_dim=False)\n",
    "\n",
    "results_dict_new = SDL_BCD_class_new.fit(iter=iteration, subsample_size=None,\n",
    "                                                beta = beta,\n",
    "                                                search_radius_const=np.linalg.norm(X_train),\n",
    "                                                update_nuance_param=False,\n",
    "                                                if_compute_recons_error=False, if_validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "conf_matrix_dynamics = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(conf_matrix_dynamics)\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "print('F1: %.3f' % f1_score(y_test, y_pred))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903505ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = y\n",
    "under_sampler = RandomUnderSampler()\n",
    "X_res, y_res = under_sampler.fit_resample(pd.concat([df_dynamics, base], axis=1, join='inner').copy(), Y_data)\n",
    "Y_baseline = X_res.baseline_width\n",
    "Y_data = y_res\n",
    "\n",
    "#baseline model\n",
    "length = len(Y_baseline[Y_baseline==False])\n",
    "Y_baseline[random.sample(list(Y_baseline[Y_baseline==False].index),length//2)] = True\n",
    "conf_matrix_baseline = confusion_matrix(y_true=Y_data, y_pred=Y_baseline)\n",
    "print(conf_matrix_baseline)\n",
    "print('Precision: %.3f' % precision_score(Y_data, Y_baseline))\n",
    "print('Recall: %.3f' % recall_score(Y_data, Y_baseline))\n",
    "print('F1: %.3f' % f1_score(Y_data, Y_baseline))\n",
    "print('Accuracy: %.3f' % accuracy_score(Y_data, Y_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1849f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results_dict_new, open('temp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbe2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = r\n",
    "nrow = 6+1\n",
    "num_nodes = 20\n",
    "fig, axs = plt.subplots(ncols=ncol, nrows=nrow, figsize=(ncol*4, nrow*4))\n",
    "sorted_indices = np.argsort(results_dict_new[\"loading\"][1][0][1:])[::-1]\n",
    "for i in range(ncol):\n",
    "    ind = sorted_indices[i]\n",
    "    \n",
    "    #learned adjacency matrix\n",
    "    df_adj = pd.DataFrame(results_dict_new[\"loading\"][0].T[ind][0:400].reshape(-1, 20))\n",
    "    G = nx.from_pandas_adjacency(df_adj)\n",
    "    edges = G.edges()\n",
    "    weights = [300*G[u][v]['weight'] for u,v in edges] #weight of learned adjacency matrix\n",
    "    \n",
    "    deg_seq = sorted((d for n, d in G.degree(weight='weight')), reverse=True)\n",
    "    axs[6, i].plot(deg_seq, \"b-\", marker=\"o\")\n",
    "        \n",
    "    \n",
    "    for j in range(nrow-1):\n",
    "        col_adj = results_dict_new[\"loading\"][0].T[ind][0+j*10*400:400+j*10*400].reshape(-1, 20)\n",
    "        \n",
    "        G1 = nx.Graph()\n",
    "        for a in range(num_nodes):\n",
    "            for b in range(num_nodes):\n",
    "                u = list(G.nodes())[a]\n",
    "                v = list(G.nodes())[b]\n",
    "                if G.has_edge(u,v) and u!=v:\n",
    "                    if col_adj[u, v] == 0: #all synchronizing edges\n",
    "                        G1.add_edge(u,v, color='r')\n",
    "                    else:\n",
    "                        G1.add_edge(u,v, color='b')\n",
    "        \n",
    "        edges = G1.edges()\n",
    "        colors = [G1[u][v]['color'] for u,v in edges]\n",
    "        nx.draw(G1, edge_color=colors,width=weights, ax=axs[j, i], pos = nx.spring_layout(G1, seed=123))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #sns.heatmap(results_dict_new[\"loading\"][0].T[ind][0+j*10*400:400+j*10*400].reshape(-1, 20),\n",
    "                    #ax = axs[j, i])\n",
    "        if j == 0:\n",
    "            axs[j, i].title.set_text(str(round(results_dict_new[\"loading\"][1][0][1:][sorted_indices[i]], 3))\n",
    "                                 +\"\\ntime\"+str(j*10))\n",
    "        else:\n",
    "            axs[j, i].title.set_text(\"time\"+str(j*10))\n",
    "\n",
    "        \n",
    "    rect = plt.Rectangle((0.12+i*0.1, 0.12), 0.09, 0.78, fill=False, color=\"k\", lw=1, \n",
    "                         zorder=1000, transform=fig.transFigure, figure=fig)\n",
    "    fig.patches.extend([rect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"temp.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7b097",
   "metadata": {},
   "source": [
    "# <B, WT> examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/implementation-of-logistic-regression-from-scratch-using-python/\n",
    "class LogitRegression() :\n",
    "    def __init__( self, learning_rate, iterations ) :        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training    \n",
    "    def fit( self, X, Y ) :        \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        self.m, self.n = X.shape \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()  \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        # calculate gradients        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(\"../data/random_graph/ucla_20walk_graph_features.csv\")\n",
    "results_dict_new = pickle.load(open('../data/dynamics_pairs/fca_k8_ucla_20walk_colored_adj_sdl_dict.pkl', 'rb'))\n",
    "coef_idx = np.argsort(results_dict_new[\"loading\"][1][0][1:])[::-1]\n",
    "print(df_features.loc[y_train.index, :].num_edges.idxmax())\n",
    "print(df_features.loc[y_train.index, :].num_clique.idxmax())\n",
    "print(df_features.loc[y_train.index, :].num_edges.idxmin())\n",
    "print(df_features.loc[y_train.index, :].num_clique.idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2241f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = [1176, 4746, 13, \n",
    "       y_train.index[10], y_train.index[1], y_train.index[2], y_train.index[3], y_train.index[4]]\n",
    "ind_title = [\"Largest #edges\", \"Smallest #edges\", \"Largest #cliques\", \"\", \"\", \"\", \"\", \"\"]\n",
    "\n",
    "ncol = 8\n",
    "nrow = 4\n",
    "fig, axs = plt.subplots(ncols=ncol, nrows=nrow, figsize=(ncol*4, nrow*4))\n",
    "num_nodes=20\n",
    "\n",
    "for i in range(8):\n",
    "    model = LogitRegression(learning_rate = 0.01, iterations = 1000)\n",
    "    x = np.array([np.matmul(results_dict_new[\"loading\"][0].T, \n",
    "                            X_train[list(y_train.index).index(ind[i]),:].T).T])\n",
    "    model.fit(x, np.array(y_train[ind[i]])) \n",
    "    W = np.array(model.W)\n",
    "    print(np.array(y_train[ind[i]]), \": \", model.predict(x))\n",
    "    print(np.array(df_dynamics)[ind[i], -20:])\n",
    "    #print()\n",
    "    \n",
    "    axs[i//ncol, i%ncol].title.set_text(ind_title[i]+\" (\"+str(np.array(y_train[ind[i]])) + \")\")\n",
    "    axs[i//ncol, i%ncol].imshow(np.array([model.W[coef_idx]]))\n",
    "    \n",
    "    df_adj = df_graph[:, ind[i]].reshape(20, 20)\n",
    "    #df_adj = np.array(X)[ind[i],:400].reshape(-1, 20)\n",
    "    G = nx.Graph()\n",
    "    G = nx.from_pandas_adjacency(pd.DataFrame(df_adj))\n",
    "    \n",
    "    iter = [1, 20, 50]\n",
    "    for j in range(3):\n",
    "        col_adj = X_train[list(y_train.index).index(ind[i]), \n",
    "                          (0+iter[j]*400):(400+iter[j]*400)].reshape(-1, num_nodes)\n",
    "        \n",
    "        G1 = nx.Graph()\n",
    "        for a in range(num_nodes):\n",
    "            for b in range(num_nodes):\n",
    "                u = list(G.nodes())[a]\n",
    "                v = list(G.nodes())[b]\n",
    "                if G.has_edge(u,v) and u!=v:\n",
    "                    if abs(col_adj[u, v])==0: #< 0.03: #all synchronizing edges\n",
    "                        G1.add_edge(u,v, color='r')\n",
    "                    else:\n",
    "                        G1.add_edge(u,v, color='b')\n",
    "        \n",
    "        edges = G1.edges()\n",
    "        colors = [G1[u][v]['color'] for u,v in edges]\n",
    "        nx.draw(G1, edge_color=colors, node_size= 50, ax=axs[i//ncol+1+j, i%ncol], pos = nx.spring_layout(G1, seed=123))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
